# BioCreative VI â€” Track 5: text mining chemical-protein interactions (ChemProt)

This code presents our system for the
[ChemProt task](https://biocreative.bioinformatics.udel.edu/tasks/biocreative-vi/track-5/).


## Requirements

Ubuntu, Python 3.6.4. Install the required packages:
```
$ pip install -r requirements.txt
```


## Usage

### Scripts

[confusion.py](src/confusion.py):
Calculate the confusion matrix and other statistics given a file with
predicted relations.

[create_embeddings.py](src/create_embeddings.py):
Create pre-trained part-of-speech and dependency embedding vectors.

[main.py](src/main.py):
Train a deep learning model and test it. The deep learning model can
be a bidirectional long short-term memory (BiLSTM) recurrent network
or a convolutional neural network (CNN). It is necessary to edit the
script to choose the different input arguments. Only the seed number
can be passed by command line:
```
$ python main.py 2
```

[mfuncs.py](src/mfuncs.py):
Functions used by the [main.py](src/main.py) script.

[support.py](src/support.py):
Auxiliary code to treat the ChemProt dataset.

[utils.py](src/utils.py):
General use utilities.

[voting.py](src/voting.py):
Average several outputs (probabilities). Edit the script to choose
the input directory and the group to be evaluated.

### Datasets

The datasets were pre-processed (tokenization, sentence splitting,
part-of-speech tagging, and dependency parsing) by the [Turku Event
Extraction System (TEES)](https://github.com/jbjorne/TEES).
Available for download as `data.zip`
[\[Mirror 1\]](https://uapt33090-my.sharepoint.com/:f:/g/personal/ruiantunes_ua_pt/EuElDML6aytMtyxAHuwK63wBbraItRDtadpegOZOPVa2Og?e=FRkNjT)
[\[Mirror 2\]](https://drive.google.com/drive/folders/1psUqCTxik1mWZ8rNbmrLVYtoTmMdd9Np?usp=sharing):

* [ChemProt](https://biocreative.bioinformatics.udel.edu/tasks/biocreative-vi/track-5/):
  `sample`, `training`, `development`, and `test_gs`.

* [BioGRID](https://thebiogrid.org): `biogrid`.

### Word embeddings

Our word embedding models were created from PubMed English abstracts.
We also pre-trained part-of-speech and dependency embedding vectors from
the ChemProt dataset. Available for download as `word2vec.zip`
[\[Mirror 1\]](https://uapt33090-my.sharepoint.com/:f:/g/personal/ruiantunes_ua_pt/EuElDML6aytMtyxAHuwK63wBbraItRDtadpegOZOPVa2Og?e=FRkNjT)
[\[Mirror 2\]](https://drive.google.com/drive/folders/1psUqCTxik1mWZ8rNbmrLVYtoTmMdd9Np?usp=sharing).

We also tested the word embeddings model created by Chen _et al._ (2018)
[\[Paper\]](https://arxiv.org/abs/1810.09302)
[\[Code\]](https://github.com/ncbi-nlp/BioSentVec).

### Supplementary data

Statistics about the datasets, and some prediction files.
Available for download as `supp.zip`
[\[Mirror 1\]](https://uapt33090-my.sharepoint.com/:f:/g/personal/ruiantunes_ua_pt/EuElDML6aytMtyxAHuwK63wBbraItRDtadpegOZOPVa2Og?e=FRkNjT)
[\[Mirror 2\]](https://drive.google.com/drive/folders/1psUqCTxik1mWZ8rNbmrLVYtoTmMdd9Np?usp=sharing).


## Reference

If you use this code or data in your work, please cite
[our publication](https://doi.org/10.1093/database/baz095):

```
@article{antunes2019a,
  author    = {Antunes, Rui and Matos, S{\'e}rgio},
  journal   = {Database},
  month     = oct,
  number    = {baz095},
  publisher = {{Oxford University Press}},
  title     = {Extraction of chemical--protein interactions from the literature using neural networks and narrow instance representation},
  url       = {https://doi.org/10.1093/database/baz095},
  volume    = {2019},
  year      = {2019},
}
```
